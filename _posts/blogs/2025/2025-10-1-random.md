---
layout: post
title: 年轻人开始烧香拜佛
excerpt: "对年轻人现代崇拜的一点观察"
modified: 2025-9-1
tags: [随机性, 上香]
comments: true
category: blog
---



年轻人在上班和上进之间选择了上香，成了最近的网络流行语。甚至老人都开始不上香了，为什么年轻人开始返祖呢，这引起了我的思考。





## 随机性

先从随机性开始说起吧，从小我们就开始抛掷硬币来辅助做一些随机决定，因为我们的认知中这个过程是随机的，是无法被我们预测的，然而 Diaconis等人（2007）研究了若干投掷机器（coin tossing machine），如下图所示：

![tossing-machine](/assets/blog-images/2025/tossing-machine.png)

他们发现，在“精确调整”这种装置时，可以使“起始正面朝上 → 落下时正面朝上”几乎 100 % 地成立（即可控性非常好）——这说明：如果初始状态（位置、角动量、线速度等）精确且重现性高，是可以“决定”结果的。尽管实验室中可以严格控制，在实际操作中，要保证每次抛掷的初始条件足够精确仍然是及其困难的，因此仍然有一定的随机性。

其实，所谓随机性，多半来自我们不知道成因、也无法控制那些微小的因子。一旦能知道原因、掌控变量，“随机”就不复存在，一切都会变得可预期、可重复，尽在人类掌握。



## 古代崇拜

对于古人来说，这一趟出去打猎或者捕鱼，其实是个随机事件，能否打到猎物纯粹看天（概率）。种粮食后，什么时候能下雨，粮食会不会有收成，依然是不确定的，说不定就干旱了，又说不定就洪涝了。这种不确定的力量，只能让古人对未知的神秘力量产生崇拜，祭天拜地，祈求来年的风调雨顺。今天的人类弄明白了很多原理，只要像上方投掷筛子的机器那样，控制好变量，就会有确定的结果，于是人类不再盲目崇拜了。

以前的基督徒，吃饭之前都要祷告，桌上的一切都是上天的赏赐。今天的人类很难再有同等的感慨，牛排可以去超市买到，粮食可以超市买到，对于这些轻易可以获得的东西，人类再难有崇拜之心了。



## 现代崇拜

### 大语言模型的不确定性

基本的吃饭问题解决之后，人类开始有更多的疑问。就以大语言模型为例，不同的人用同一个提示词在同一个模型问问题，得到的答案也不一样，甚至同一个人不同的时候问同一个问题，回答也不一样。Thinking Machines 在这篇研究[Defeating Nondeterminism in LLM Inference](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/?utm_source=chatgpt.com)中做了详细的分析，并给出了一种通用的、系统级别的解释框架：即在并行计算、Kernel 实现与 reduction 操作中，不同的 batch 分割、不同的并行路径、不同的归约顺序等，可能导致浮点计算的微小差异，继而在“最大概率 token 选择”（greedy decoding）时造成不一致输出。还有不少研究也有同样的发现，相同 prompt + 相同设置（包括 temperature = 0）下依然可能得到不同输出。

综合现有资料，以下是目前较为被接受或正在讨论的机制／原因：

| **原因**                                  | **说明**                                                     |
| ----------------------------------------- | ------------------------------------------------------------ |
| **浮点数精度和运算顺序差异**              | 在并行硬件（GPU、多核）上，浮点运算并不是严格可交换的（a + b + c 与 (a + b) + c 有可能有微小差异）。当操作被划分、合并、重排序时，这些微小差异会被放大，导致 logits 或 softmax 概率出现极其微小差别，从而在 greedy 选择时选择不同 token。 |
| **批量大小 / 分批 (batching) 的非不变性** | 如果推理系统是把多个请求或多个 prompt/标记打包（batch）一起处理，那么内部 kernel（如矩阵乘法、归约、attention）可能根据 batch 大小、线程分划、split-reduction 策略等调整计算结构，从而改变数值计算路径。Thinking Machines 提出的 “batch invariance” 正是针对这一问题。 |
| **tie-breaking（并列最高概率 token）**    | 如果在某一步骤中，有两个或多个 token 的概率极为接近（或在计算误差层面几乎相等），系统可能需要有机制（如固定顺序、hash、内存地址、实现细节）来打破 tie。不同实现可能选择不同的打破方式。 |
| **内存、并行性、kernel 优化策略**         | 推理库、底层计算库、编译器优化、线程调度、缓存、内存布局、通信延迟等都可能引入不可控的次级差异。 |
| **模型架构（如 MoE 路由）**               | 如果模型使用 Mixture-of-Experts（专家网络）架构，那么对 token 的路由选择（哪个专家处理哪个 token）可能受到容量限制、负载均衡等因素影响；在不同请求上下文中，路由可能略有不同，从而对最终输出有所影响。 |
| **系统级变化（如负载、并发、资源竞争）**  | 在云服务、API 服务环境中，请求处理可能被打包、排队、和其他请求一起并行执行。不同时间的系统负载或资源分配可能导致关联操作被放入不同批、不同计算路径，从而引入输出差异。 |



大语言模型的这一特点告诉我们，今天人类这么强大，让自己研发的大模型有个稳定的输出都是困难的，这里有太多偶然性，



### 短视频

今天的年轻人想通过短视频或者直播来赚钱的太多啦，但是这件事情也是充满着不确定性的，谁也不知道自己哪条视频会火，即便你已经按照官方的建议一一去做了，各大网红分享的招数也都使用了，也注意到了拍摄节奏、封面配色、标题长度、发布时间、互动策略，但是就是没有流量，而另一条随手拍的视频，却莫名其妙地上了热榜。甚至推荐算法本身的研发人都无法准确知道哪条视频会火，在这种情况下，必然就会产生类似于古代的算法崇拜，年轻人开始研究算法，一如古人研究天象，试图揣摩推荐系统的“心意”，或者开始转向更神秘的解释，是不是自己最近人品、运气、磁场不太强，是不是“上香”能带来好运？

在这种情况下，人们对算法的敬畏与焦虑，与古人面对未知世界时的祈祷，其实并无二致。唯一的区别是，古人祈求风调雨顺，而我们祈求“推流顺利”。



### 炒股

炒股也是如此，即便量化交易已经非常火爆，但是依然没有办法做到 100%预测，要是能做到100%预测，也就没有股市了，也再没有人来以小博大了。

量化交易的盛行并没有消除这种不确定性，反而让它变得更精密、更高维。算法在与算法博弈，机器人之间的决策链条复杂得连程序员都无法完全解释。当我们盯着屏幕，看着红绿闪烁的K线，试图从中寻找“趋势”的迹象时，心理上其实与古人占卜龟甲、解读天象别无二致——我们都在用理性包裹着不确定，试图让不可知变得可控。



## 总结

一代人有一代人的崇拜，我们总觉得古人愚昧，例如吃饱饭还要感谢上帝。随着技术越来越先进，人类一定能完全掌握导致现代崇拜的变量，让这件事不再神秘，但是一定又会产生新的未解之谜。那天看到[北大学生在文创店排大队领取免费新生礼](https://mp.weixin.qq.com/s/8BkMbI5pvShK6sNsPtRIAw)，这跟老头老太太领取免费鸡蛋又有什么区别呢？







## 参考文献

- Diaconis, Persi, Susan Holmes, and Richard Montgomery. “Dynamical Bias in the Coin Toss.” *SIAM Review*, vol. 49, no. 2, 2007, pp. 211–235. Society for Industrial and Applied Mathematics, doi:10.1137/S0036144504446436 .
- Ouyang, S., Zhang, J. M., Harman, M., & Wang, M. (2023). *An empirical study of the non-determinism of ChatGPT in code generation*. arXiv. https://arxiv.org/abs/2308.02828
- Song, Y., Wang, G., Li, S., & Lin, B. Y. (2024). *The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism*. arXiv. https://arxiv.org/abs/2407.10457  
